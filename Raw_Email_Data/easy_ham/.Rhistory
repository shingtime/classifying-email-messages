########## Basic vectorization of R ##########
## R use plenty of simple vectorization.
# help (known function): ?"function"
# help (unknown function): ??"function"
x = rnorm(n=10)
x
x+1 # adds one to all elements of the vector
y = c(1:10) # y = 1:10
x + y # elementwise addition
y^2 # elementwise squaring
exp(x) # elementwise exponentiating
########## Get familar with the distributions in R #########
# dpqr; d: density, p: cdf, q: quantile function,
# r: generating random variables
# norm: normal dist.
# beta: beta dist.
# gamma: gamma dist.
# binom: binomial dist.
# ...etc.
########## MC example ##########
# E[cos(X)] where X ~ N(0,1)
m = 1000000
sample = rnorm(n=m,mean=0,sd=1) #1
Cosine = cos(sample) #2
EcosX = mean(Cosine) #3
E_cos_X = mean(cos(rnorm(n=m,mean=0,sd=1)))
E_cos_X
# Smaller Monte Carlo sample size:
m = 1000
m = 100
# Repeat 100 times, see how much the answer varies...
nreps = 100
E_cos_X = rep(NA,nreps)
for (i in 1:nreps){
E_cos_X[i] = mean(cos(rnorm(n=m,mean=0,sd=1)))
}
summary(E_cos_X)
# Lets try different sample sizes...
pseq = 1:6
mseq = 10^pseq
nreps = 100
compute_time = rep(NA,length(pseq))
E_cos_X = matrix(NA,nrow=nreps,ncol=length(mseq))
colnames(E_cos_X) = paste("n_10_to",pseq)
for (i in 1:length(mseq)){
# Set the MC sample size and repeat:
m = mseq[i]
ct = system.time({
for (j in 1:nreps){
E_cos_X[j,i] = mean(cos(rnorm(n=m,mean=0,sd=1)))
}
})["elapsed"]
cat(paste0("Finished ",nreps," replicates with m=",m," in ",round(ct,4)," seconds...\n"))
compute_time[i] = ct
}
head(E_cos_X)
## larger sample size will give more accurate result, but with longer computing time.
boxplot(E_cos_X,main="MC Variability as a Function of MC Sample Size",ylab="Estimate of E[cos(X)]",xlab="Sample Size")
summary(E_cos_X)
plot(y=apply(E_cos_X,2,sd),x=1:ncol(E_cos_X),xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
# Zoom in:
plot(y=apply(E_cos_X,2,sd)[4:6],x=4:6,xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
# Compute time:
plot(y=compute_time/nreps,x=pseq,xlab="log_{10}(n)",ylab="Compute Time",main="Computation Time vs MC Sample Size",type="b")
##########
# Monte Carlo to find posterior summaries:
# From class:
alpha <- 1.111
beta <- 49*alpha
y <- 0
n <- 10
# Posterior is Beta(alpha+y,beta+n-y)
# Central 95% interval (calculated directly, without MC)
qbeta(c(0.025,0.975),alpha+y,beta+n-y)
# Central 95% Interval using Monte Carlo (you shouldonly do this if you can't get it analytically!):
m = 10000
quantile(p=c(0.025,0.975),rbeta(n=m,alpha+y,beta+n-y))
boxplot(E_cos_X,main="MC Variability as a Function of MC Sample Size",ylab="Estimate of E[cos(X)]",xlab="Sample Size")
plot(y=apply(E_cos_X,2,sd),x=1:ncol(E_cos_X),xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
plot(y=apply(E_cos_X,2,sd)[4:6],x=4:6,xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
plot(y=compute_time/nreps,x=pseq,xlab="log_{10}(n)",ylab="Compute Time",main="Computation Time vs MC Sample Size",type="b")
quantile(p=c(0.025,0.975),rbeta(n=m,alpha+y,beta+n-y))
########## Basic vectorization of R ##########
########## Basic vectorization of R ##########
## R use plenty of simple vectorization.
# help (known function): ?"function"
# help (unknown function): ??"function"
x = rnorm(n=10)
x
x+1 # adds one to all elements of the vector
y = c(1:10) # y = 1:10
x + y # elementwise addition
y^2 # elementwise squaring
exp(x) # elementwise exponentiating
########## Get familar with the distributions in R #########
# dpqr; d: density, p: cdf, q: quantile function,
# r: generating random variables
# norm: normal dist.
# beta: beta dist.
# gamma: gamma dist.
# binom: binomial dist.
# ...etc.
########## MC example ##########
# E[cos(X)] where X ~ N(0,1)
m = 1000000
sample = rnorm(n=m,mean=0,sd=1) #1
Cosine = cos(sample) #2
EcosX = mean(Cosine) #3
E_cos_X = mean(cos(rnorm(n=m,mean=0,sd=1)))
E_cos_X
# Smaller Monte Carlo sample size:
m = 1000
m = 100
# Repeat 100 times, see how much the answer varies...
nreps = 100
E_cos_X = rep(NA,nreps)
for (i in 1:nreps){
E_cos_X[i] = mean(cos(rnorm(n=m,mean=0,sd=1)))
}
summary(E_cos_X)
# Lets try different sample sizes...
pseq = 1:6
mseq = 10^pseq
nreps = 100
compute_time = rep(NA,length(pseq))
E_cos_X = matrix(NA,nrow=nreps,ncol=length(mseq))
colnames(E_cos_X) = paste("n_10_to",pseq)
for (i in 1:length(mseq)){
# Set the MC sample size and repeat:
m = mseq[i]
ct = system.time({
for (j in 1:nreps){
E_cos_X[j,i] = mean(cos(rnorm(n=m,mean=0,sd=1)))
}
})["elapsed"]
cat(paste0("Finished ",nreps," replicates with m=",m," in ",round(ct,4)," seconds...\n"))
compute_time[i] = ct
}
head(E_cos_X)
## larger sample size will give more accurate result, but with longer computing time.
boxplot(E_cos_X,main="MC Variability as a Function of MC Sample Size",ylab="Estimate of E[cos(X)]",xlab="Sample Size")
summary(E_cos_X)
plot(y=apply(E_cos_X,2,sd),x=1:ncol(E_cos_X),xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
# Zoom in:
plot(y=apply(E_cos_X,2,sd)[4:6],x=4:6,xlab="log_{10}(n)",ylab="Monte Carlo SD",main="MC Standard Deviation",type="b")
# Compute time:
plot(y=compute_time/nreps,x=pseq,xlab="log_{10}(n)",ylab="Compute Time",main="Computation Time vs MC Sample Size",type="b")
##########
# Monte Carlo to find posterior summaries:
# From class:
alpha <- 1.111
beta <- 49*alpha
y <- 0
n <- 10
# Posterior is Beta(alpha+y,beta+n-y)
# Central 95% interval (calculated directly, without MC)
qbeta(c(0.025,0.975),alpha+y,beta+n-y)
# Central 95% Interval using Monte Carlo (you shouldonly do this if you can't get it analytically!):
m = 10000
quantile(p=c(0.025,0.975),rbeta(n=m,alpha+y,beta+n-y))
example(sum)
help(sum)
help(barplot)
exmaple(min)
example(min)
help(min)
rep(1:5,3)
list.file()
list.files()
sd<-c(22.33.44)
sd<-c(22,33,44)
sd
sd*2
sd[1]
sd[[2]]
ssd[2]<-12
sd[2]<-12
sd
sd<-vector[1,2,3,4]
seq(5,9)
help(contour)
aaa<-matrix(2,3,3)
contour(aaa)
aaa[1,3]<-0
contour(aaa)
persp(aaa)
persp(aaa,expand=0.2)
contour(vocano)
library(vocano)
help(omage)
help(image)
library("grid", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
help(abline)
help(as.integer())
help(as.integer)
help(levels)
help(plot)
help(dataframe)
help(data.frame)
install.packages("ggpolt")
install.packages("ggplot")
install.packages("ggplot2")
demo(graphics)
demo(image)
help(ggplot)
help(package="ggplot")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(ggplot)
help("ggplot2")
getwd()
setwd("/User/Bruce/Desktop")
getwd()
?rnorm
update
i=0
if i>25{
break
else{
print(i)
i=i+5
}
}
i=0
while (i<=25){
print(i)
i=i+5
}
for (i in 1:5){
print(i)
}
install.packages(c("aplpack", "boot", "cluster", "codetools", "devtools", "formatR", "Hmisc", "htmltools", "httr", "jsonlite", "KernSmooth", "labeling", "markdown", "MASS", "mgcv", "mime", "Rcpp", "rmarkdown", "swirl", "UsingR"))
library(mydataset)
library(datasets)
data(mycars)
ls()
ls(datasets)
summary(datasets)
help(datasets)
library(help="datasets")
data(mtcars)
View(mtcars)
library(mydataset)
data(mtcars)
View(mtcars)
lm1<-lm(mpg~drat,data=mtcars)
lm2<-lm(mpg~drat+wt,data=mtcars)
lm3<-lm(mpg~drat+wt+qsec,data=mtcars)
anova(lm1,lm2,lm3)
??glm
help)glm
help(glm)
x = seq(0, 100)
z = outer(x, x, nodeDensity)
max(z)
source(url("http://eeyore.ucdavis.edu/stat141/homework/nodeDensity.R"))
x = seq(0, 100)
z = outer(x, x, nodeDensity)
max(z)
x = 0:100
z = outer(x, x, nodeDensity)
persp(x, x, z, col = "lightblue", theta = 40, phi = 40,
xlab = "0 to 100",  ylab = "0 to 100")
r = x[row(z)[ z == max(z)]]
c = x[col(z)[ z == max(z)]]
r
r
c
library(MASS)
source(url("http://eeyore.ucdavis.edu/stat141/homework/nodeDensity.R
"))
library(MASS)
source(url("http://eeyore.ucdavis.edu/stat141/homework/nodeDensity.R"))
x = seq(0, 100)
y = seq(0, 100)
z = outer(x, y, nodeDensity)
par(mfrow=c(1,1))
PDF('rplot.pdf')
graph1 = contour(x,y,z)
dev.off()
236.558/80
138.327/4
98.231/76
content.type = 'multipart/alternative; boundary=2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1'
content.type.q = 'multipart/alternative; boundary="2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1"'
splitted = strsplit(content.type, '=')
splitted = splitted[[1]][2]
splitted
gsub('"', '', splitted)
splitted.q = strsplit(content.type.q, '=')
splitted.q = splitted.q[[1]][2]
splitted.q
gsub('"', '', splitted.q)
boundary = function(content_type){
boundary_str = strsplit(content_type, "=")[[1]][2]
gsub('"', '', boundary_str)
}
content.type = 'multipart/alternative; boundary=2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1'
content.type.q = 'multipart/alternative; boundary="2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1"'
extract.boundary = function(x) {
# Extract the boundary from string x.
boundary.str = strsplit(x, '=')[[1]][2]
# Get rid of quotes (if any).
gsub('"', '', boundary.str)
content.type = 'multipart/alternative; boundary=2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1'
content.type.q = 'multipart/alternative; boundary="2063203.1026378321083.JavaMail.root.abv-sfo1-ac-agent1"'
# Split on '=' and only take the second piece.
splitted = strsplit(content.type, '=')
splitted = splitted[[1]][2]
# Split in the quotes case.
splitted.q = strsplit(content.type.q, '=')
splitted.q = splitted.q[[1]][2]
# Remove quotes.
gsub('"', '', splitted)
# We can turn this into a function.
extract.boundary = function(x) {
# Extract the boundary from string x.
boundary.str = strsplit(x, '=')[[1]][2]
# Get rid of quotes (if any).
gsub('"', '', boundary.str)
}
extract.boundary(content.type)
extract.boundary(content.type.q)
5.83e+03
0.191/0.028
setwd("/Users/Bruce/Desktop/STA 141 assignment3/SpamAssassinTraining/easy_ham")
file = "01216.e30b39890b41cf8740b3315f79521f59"
file = readLines(file)
file
head_body = match("",file)
head_body
header = file[2:(head_body-1)]
header
header = get_header(header)
get_header = function(header){
header = textConnection(header)
header = read.dcf(header,all = TRUE)
header_v = c(t(header))
names(header_v) = names(header)
unlist(header_v)
}
extract_boundary = function(ContentType){
grepl("boundary", ContentType== TRUE)
boundary = strsplit(ContentType,'=')
boundary = boundary[[1]][2]
boundary = gsub('"', '', boundary)
boundary
}
split_body = function(header,body){
## generate the boundary
boundary = extract_boundary(header["Content-Type"])
## if the body doesn't contain any attachements, we just return the original body message
if(is.null(boundary) || is.na(boundary)){
return(list(body_message = body))
}
## Usually ,the boundary line will start with "--" , so I need to generate a new string to combine these seperated strings.
string_begin = paste("--",boundary,sep="")
string_end = paste(string_begin,"--",sep="")
## Now I need to generate the boundry string at the end of the corresponding attachment
## figure out the line numbers where the boundary string appears
## for beginning part, if length(begin) >0 , it means there are several attachment
begin_1 = which(body == string_begin)
end_1 = which(body == string_end)
## consider cases that some attachments end at the end of the whole body.
if(length(begin)==1 & length(end)==0){
end = length(body)
}
## since there maybe have multiple attachement, we need to sort all the "begin" and "end" and figure it out what are the rest of the messages.
position_1 = sort(c(begin_1, end_1))
if (length(position_1) == 0){
print("Cannot find boundary for the attachment")
return(list(body_no = body))
}
position_min_1 = min(position_1)
position_max_1 = max(position_1)
## generate the rest of the body part
rest_body = body[-seq(position_min_1,position_max_1)]
## generate the attachment part
## We should use the exactly same way to split header as what I have done for
attachment = body[seq(position_min_1,position_max_1)]
## In order to split the attachment, I need to relocate the location of boundary line.
begin_2 = which(attachment == string_begin)
end_2 = which(attachment == string_end)
position_2 = sort(c(begin_2, end_2))
## split the attachments
attachments = list()
for(i in 1:(length(position_2)-1)) {
## find the attachment between two boundary, which is a attachment.
part = (position_2[i] + 1):(position_2[i+1]-1)
attachments[[i]] = splitAttachment(attachment[part])
}
list(body=rest_body,attachment = attachments)
}
splitAttachment =
function(input)
{
attach_sep = match("", input)
header = input[1:(attach_sep-1)]
## call header function which is defined before
header = get_header(header)
list(header = header, body = input[-c(1:attach_sep)])
}
header = get_header(header)
header
body  = file[(head_body+1):length(file)]
body
real_body = split_body(header,body)
split_body = function(header,body){
## generate the boundary
boundary = extract_boundary(header["Content-Type"])
## if the body doesn't contain any attachements, we just return the original body message
if(is.null(boundary) || is.na(boundary)){
return(list(body_message = body))
}
## Usually ,the boundary line will start with "--" , so I need to generate a new string to combine these seperated strings.
string_begin = paste("--",boundary,sep="")
string_end = paste(string_begin,"--",sep="")
## Now I need to generate the boundry string at the end of the corresponding attachment
## figure out the line numbers where the boundary string appears
## for beginning part, if length(begin) >0 , it means there are several attachment
begin_1 = which(body == string_begin)
end_1 = which(body == string_end)
## consider cases that some attachments end at the end of the whole body.
if(length(begin_1)==1 & length(end_1)==0){
end = length(body)
}
## since there maybe have multiple attachement, we need to sort all the "begin" and "end" and figure it out what are the rest of the messages.
position_1 = sort(c(begin_1, end_1))
if (length(position_1) == 0){
print("Cannot find boundary for the attachment")
return(list(body_no = body))
}
position_min_1 = min(position_1)
position_max_1 = max(position_1)
## generate the rest of the body part
rest_body = body[-seq(position_min_1,position_max_1)]
## generate the attachment part
## We should use the exactly same way to split header as what I have done for
attachment = body[seq(position_min_1,position_max_1)]
## In order to split the attachment, I need to relocate the location of boundary line.
begin_2 = which(attachment == string_begin)
end_2 = which(attachment == string_end)
position_2 = sort(c(begin_2, end_2))
## split the attachments
attachments = list()
for(i in 1:(length(position_2)-1)) {
## find the attachment between two boundary, which is a attachment.
part = (position_2[i] + 1):(position_2[i+1]-1)
attachments[[i]] = splitAttachment(attachment[part])
}
list(body=rest_body,attachment = attachments)
}
real_body = split_body(header,body)
real_body
list(email_header = header, whole_body = real_body)
split_email("01216.e30b39890b41cf8740b3315f79521f59")
split_email = function(file){
file = readLines(file)
## find the boundary for head and body in the email.
head_body = match("",file)
header = file[2:(head_body-1)]
## get the formatted header part
header = get_header(header)
body  = file[(head_body+1):length(file)]
## get the body part with splitted attachment
real_body = split_body(header,body)
list(email_header = header, whole_body = real_body)
}
split_email("01216.e30b39890b41cf8740b3315f79521f59")
split_email = function(file){
file = readLines(file)
## find the boundary for head and body in the email.
head_body = match("",file)
header = file[2:(head_body-1)]
## get the formatted header part
header = get_header(header)
body  = file[(head_body+1):length(file)]
## get the body part with splitted attachment
real_body = split_body(header,body)
list(email_header = header, real_body)
}
split_email("01216.e30b39890b41cf8740b3315f79521f59")
setwd("/Users/bruce/Desktop/STA 141 assignment3/SpamAssassinTraining")
dirs = list.files()
dirs
paths = list.flies("/Users/bruce/Desktop/STA 141 assignment3/SpamAssassinTraining",recursive=TRUE)
paths = list.files("/Users/bruce/Desktop/STA 141 assignment3/SpamAssassinTraining",recursive=TRUE)
paths
file = readLines("01216.e30b39890b41cf8740b3315f79521f59")
setwd("/Users/Bruce/Desktop/STA 141 assignment3/SpamAssassinTraining/easy_ham")
file = readLines("01216.e30b39890b41cf8740b3315f79521f59")
file
